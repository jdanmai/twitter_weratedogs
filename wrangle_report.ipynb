{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5\n",
    "## Wrangle, Gather, Assess, Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are wrangling, analyzing, and visualizing the tweet archive of the Twitter acount, @dog_rates aka WeRateDogs.\n",
    "> 'WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softwares Used\n",
    "The following packages (libraries) need to be installed. You can install these packages via conda or pip. Please revisit our Anaconda tutorial earlier in the Nanodegree program for package installation instructions.\n",
    "\n",
    "- pandas\n",
    "- NumPy\n",
    "- requests\n",
    "- tweepy\n",
    "- json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Motivation\n",
    "#### Context\n",
    "Your goal: wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations.\n",
    "\n",
    "#### Key Points \n",
    "- You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "- Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "- Cleaning includes merging individual pieces of data according to the rules of tidy data.\n",
    "- The fact that the rating numerators are greater than the denominators does not need to be cleaned. This unique rating system is a big part of the popularity of WeRateDogs.\n",
    "- You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Details\n",
    "- Data Wrangling:\n",
    "    - Gathering data\n",
    "    - Assessing Data\n",
    "    - Cleaning Data\n",
    "- Storing, analyzing, and visualizing your wrangled data\n",
    "- Reporting on \n",
    "    - your wrangling efforts\n",
    "    - data analyses and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "3 Sources:\n",
    "- .CSV containing preliminary data from WeRateDogs tweets\n",
    "- .TSV containing images; neural network analysis of dog breeds\n",
    "- Twitter API with additional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to access the Twitter API data (you need to set up a Twitter developer account and get the following:\n",
    "> - consumer_key\n",
    "> - consumer_secret\n",
    "> - access_token\n",
    "> - access_secret\n",
    "\n",
    "wait_on_rate_limit and wait_on_rate_limit_notify are set to TRUE because:\n",
    "- Twitter puts limits on number of requests\n",
    "- we're gathering data from thousands of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet information should be accessed through 'get_status'\n",
    "- the Tweet JSON data = 'tweet_json.txt' file using 'dump()' (from json module)\n",
    "- this will repear for every tweet_id in the 'archive' df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large file we just ran contains the JSON data for every tweet. We now need to create a pandas df with the info needed-\n",
    "- we can use 'listofdicts.' to create this df\n",
    "- create list and append to dictionary (JSON data )\n",
    "- .loads() will read from JSON module to interpret our text file\n",
    "\n",
    "We are focusing on \n",
    "- ID\n",
    "- retweet_count\n",
    "- favorite_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data\n",
    "- .CSV containing preliminary data from WeRateDogs tweets --> stored as <b>archive</b>\n",
    "- .TSV containing images; neural network analysis of dog breeds  --> stored as <b>img</b>\n",
    "- Twitter API with additional data --> stored as <b>json</b>\n",
    "\n",
    "We are now going to assess, clean, drop, and make these tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Assess 'archive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Assess 'img'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Assess 'json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues and Conclusions\n",
    "DQ - data quality issue\n",
    "DT - data tidiness issue\n",
    "\n",
    "#### archive\n",
    "- there are retweets and we are only looking at non-retweet data (DT)\n",
    "- there are 4 columns (doggo, floofer, pupper, and puppo) that need to collapse into one column: category (DT)\n",
    "- timestamp is not stored as a datetime format (DQ)\n",
    "- there are rows where none values =/= null values(DQ)\n",
    "- source column (archive) is not consistent (DQ)\n",
    "- there is no photo or rating for : 835246439529840640 (DQ)\n",
    "- there is an incorrect rating for: 666287406224695296\t, 810984652412424192 (DQ)\n",
    "\n",
    "#### Img\n",
    "- some columns are not very descriptive (i.e. 'p1_conf') (DQ)\n",
    "\n",
    "#### json\n",
    "- to match column titles in other 2 DFs, 'id' should be 'tweet_id' (DQ)\n",
    "\n",
    "### Overall\n",
    "Looking at all and between the 3 DFs:\n",
    "- there are records that do not match between the DFs (DQ)\n",
    "- tweet data unorganized and in multiple DFs, need to combine (DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "Steps:\n",
    "1. Copy and Combine\n",
    "2. Drop retweets\n",
    "3. Descriptive Columns for 'img'\n",
    "4. Fix Lowercases in names\n",
    "5. Timestamp Fix\n",
    "6. Incorrect Rating Fix\n",
    "7. HTML column cleanup\n",
    "8. Dog Stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Copy and Combine\n",
    "we are going to make a 'c' copy/version of the 3 DFs for 'clean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dropping retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fixing 'img' DF; renaming to more descriptive columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fixing lowercase issue in overall DF (tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Incorrect Rating Fix\n",
    "from fractions in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. HTML column cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Dog Stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4 columns 'doggo', 'floofer', pupper', and 'puppo' are and can be merged into ONE column: dog_stage\n",
    "\n",
    "Steps for this clean-up:\n",
    "- create dictionary: every tweet_id should have a corresponding 'dog stage' and the lists should be equal\n",
    "- dog_class DF derived from dictionary to be merged into 'tweet' (master DF)\n",
    "- drop 4 original dog category columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Re-arranging column (optional) \n",
    "for easier reading/digesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data\n",
    "\n",
    "the cleaned tweet DF needs to be exported to a csv file now\n",
    "This is to be stored in 'twitter_archive_master.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and Visualize\n",
    "### There are 3 questions we want to answer:\n",
    "#### 1. What are the most popular dog breeds (in terms of favorites)?\n",
    "#### 2. What are the most popular dog breeds (in terms of retweets)?\n",
    "> Is there a correlation between most favorites and most retweets?\n",
    "#### 3. Which breeds are the most highly rated, on average?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
